{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d9303f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/walder2/torch_geometric_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "import torch as tn\n",
    "import torch.optim \n",
    "from torch.nn import ModuleDict \n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import to_hetero, Linear, GATConv, HeteroConv\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "sys.path = ['/Users/walder2/kg_uq/'] + sys.path\n",
    "path_to_data = '/Users/walder2/kg_uq/recipe_data'\n",
    "\n",
    "from kg_extraction import kg_to_hetero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd9b294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_sig = torch.nn.LogSigmoid()\n",
    "\n",
    "class HeteroGNN(tn.nn.Module):\n",
    "    def __init__(self, hidden_channels, emb_dim, num_layers, edge_types, node_types):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb_dim = emb_dim\n",
    "        self.convs = tn.nn.ModuleList()\n",
    "        \n",
    "        for _ in range(num_layers):\n",
    "            conv = HeteroConv({key : GATConv((-1, -1), hidden_channels, add_self_loops=False) for key in edge_types}, aggr='sum')\n",
    "            self.convs.append(conv)\n",
    "            \n",
    "        self.lin_dict = ModuleDict({x: Linear(hidden_channels, emb_dim, bias=False) for x in node_types})\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        rv = tn.zeros(self.emb_dim)\n",
    "        \n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "            x_dict = {key: x.relu() for key, x in x_dict.items()}\n",
    "            \n",
    "        # may want to change the aggregation layer here\n",
    "        for key, x in x_dict.items():\n",
    "            rv += self.lin_dict[key](torch.mean(x, dim=0))\n",
    "        return rv\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90969aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, (kg, kg_idx), (node_map, emb_map) = kg_to_hetero(data_dir=path_to_data, \n",
    "                                                        embeddings_model=None, \n",
    "                                                        undirected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ab06652",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim = 10 \n",
    "\n",
    "edge_types = tuple(set((y for x in train for y in x.edge_types)))\n",
    "node_types = tuple((y for x in train for y in x.node_types))\n",
    "\n",
    "encoder = HeteroGNN(hidden_channels=16, num_layers=2, emb_dim=emb_dim, edge_types=edge_types, node_types=node_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8df8f49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, loss tensor(11.3430)\n",
      "Epoch 20, loss tensor(11.3430)\n",
      "Epoch 30, loss tensor(11.3430)\n",
      "Epoch 40, loss tensor(11.3430)\n",
      "Epoch 50, loss tensor(11.3430)\n",
      "Epoch 60, loss tensor(11.3430)\n",
      "Epoch 70, loss tensor(11.3430)\n",
      "Epoch 80, loss tensor(11.3430)\n",
      "Epoch 90, loss tensor(11.3430)\n",
      "Epoch 100, loss tensor(11.3430)\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "ntrain = len(train)\n",
    "optimizer = torch.optim.Adam(encoder.parameters(), lr=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.90)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    rv = tn.zeros((ntrain, emb_dim))\n",
    "    \n",
    "    for i in range(ntrain):\n",
    "        rv[i] = encoder(train[i].x_dict, train[i].edge_index_dict)\n",
    "        \n",
    "    d_ij = log_sig(tn.matmul(rv, rv.T))\n",
    "    loss = -tn.sum(tn.diag(d_ij) - tn.logsumexp(d_ij, dim=1))\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print('Epoch %s, loss %s' % (repr(epoch+1), repr(loss.detach())))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a74a4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_geometric_env",
   "language": "python",
   "name": "torch_geometric_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
